De los principales aprendizajes fue de como pasar las herramientas de aprendizaje de maquinas que usualmente estan en archivos dentro de un computador a un entorno mas facilmente reproducible y ademas de mas facil acceso.
Por ejemplo en caso de querer volver a entrenar el modelo en la entrega 1, o hacerlo periodicamente, era necesario volver a entrar al repositorio y manualmente volver a correr los pipelines para que se reentrenara, ahora se pueden dejar estos proceso de forma automatica para que se ejecuten de forma periodica o con triggers, gracias a los Dags que se implementaron, esto permite un mayor nivel de automatizacion.
Ademas se genera una interfaz para interactuar con las predicciones de los modelos que sea amigable para una persona que no esta familiarizada con codear, intentamos pensar en una persona que esta en un call center (esto dado que se supone que el trabajo es para ayudar al call center de sodai), por lo que no se necesita saber de codigo, solo introducir datos que se usaran en la prediccion y se obtiene el resultado en texto, de forma que el operador acceda a la información que necesita, que es si el cliente comprara o no el producto esa semana.
Cabe recalcar que fue de vital importancia mantener separadas las formas en las que se entrena el modelo y en la que se hacen predicciones, dado que de esta forma la generación de predicciones es mucho mas rápida y permite que cuando el usuario acceda mediante el frontend, se pueda obtener resultados bastante rapido.

Hablando de desafíos del proyecto, mantener un orden de orquestamiento de la pipeline y al mismo tiempo fue necesario abstraerse en cuanto a los datos que se estaban utilizando, por ejemplo en la entrega anterior, como el pipeline estaba dentro del mismo script donde se cargaban los datos por ejemplo, uno siempre podia consultar que dataframe estaba utilizando con comandos print(), etc, aqui era necesario saber cuales eran los datos de entrada que esperaba recibir el modelo y tener en la cabeza como se veria con las transformaciones.
En cuanto a desafios de Gradio para la interfaz, fueron principalmente de conectarlo con el mejor modelo producido en la pipeline ya mencionada y despues hacer una interfaz simple y facil de ocupar, lo cual es algo que no habiamos tenido que hacer en otro curso, pero se llegaron a ideas como el poner el tipo de entrada que se necesitaba y un ejemplo de uso ya listo en cuanto se carga la pagina.

Se menciono antes como se mejoro con respecto a la version anterior en cuanto a la forma de automatizar el proceso, en esto fue fundamental Airlfow, ya que con la forma de definir el orden de los Dags fue mucho mas sencillo, dado que es bastante intuitiva la forma en hacer un orden en donde se va de un paso a otro mediante ">", dejando de forma visual que paso precede o procede, haciendo el orquestamiento de la pipeline mucho mas sencillo, ademas de tener este proceso de forma aislada a la parte mas relacionada con el cliente, ya que esta solo toma el modelo final ya entrenado de lo que es esta pipeline.

Para finalizar, las mejoras que se podrían implementar son de mayor control sobre los dataframes que se suben, dado que actualmente no manejamos errores que podrian suceder en caso de tener dataframes que no guarden ningun parecido al dataframe original (la idea seria tener una forma de que en caso que el dataframe sea muy diferente, el programa sepa detectarlo y se detenga de forma controlada, actualmente en algunos casos se cae, lo cual es malo) ademas se podria monitorear las comparacion de metricas de entrenamiento y test, dado que estamos usando un random forest, y aunque tiene menos riesgo de overfitting que un modelo de arbol de decision comun, igualmente es propenso a caer en ese error.

En resumen esta tarea se vio como un desafio mas de infraestructura digital que de machine learning como tal, es comun en los demas ramos dedicarse a entrenar y mejorar modelos mediante scripts de python, siempre usando una interfaz como VSCode, esta entrega fue mucho mas orientada a como pasar de los scripts que se crean en local para entrenar y usar un modelo, a despues dejarlo en un ambiente reproducible y facil de ocupar para personas que no sepan de codigo, mas cercano a lo que seria un entregable real que se le pudiera dar a un cliente.

El link del video esta en la entrega de ucursos, pero se puede ver [aquí](https://youtu.be/jQGvmMOirYI)